/*
 * TensorFlow Liteæ¨ç†å¼•æ“ for Arduino Nano 33 BLE Sense Rev2
 * ç”¨æ–¼å¸•é‡‘æ£®ç—‡ç‹€åˆ†æçš„åµŒå…¥å¼æ¨ç†
 */

#ifndef TENSORFLOW_LITE_INFERENCE_H
#define TENSORFLOW_LITE_INFERENCE_H

#include <Arduino.h>
#include <TensorFlowLite.h>
#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/schema/schema_generated.h"
#include "tensorflow/lite/micro/micro_log.h"
#include "model_data.h"

class TensorFlowLiteInference {
private:
    // TensorFlow Liteç›¸é—œå°è±¡
    const tflite::Model* model;
    tflite::MicroInterpreter* interpreter;
    tflite::AllOpsResolver* resolver;
    
    // è¼¸å…¥è¼¸å‡ºå¼µé‡
    TfLiteTensor* input;
    TfLiteTensor* output;
    
    // å…§å­˜åˆ†é…
    static constexpr int kTensorArenaSize = 60 * 1024;  // 60KB
    uint8_t tensor_arena[kTensorArenaSize];
    
    // æ¨¡å‹åƒæ•¸
    static constexpr int kSequenceLength = 50;
    static constexpr int kFeatureDim = 9;
    static constexpr int kNumClasses = 5;
    
    // æ•¸æ“šç·©è¡å€
    float input_buffer[kSequenceLength * kFeatureDim];
    int buffer_index;
    bool buffer_full;
    
    // é æ¸¬çµæœ
    float predictions[kNumClasses];
    int predicted_class;
    float confidence;
    
public:
    TensorFlowLiteInference();
    ~TensorFlowLiteInference();
    
    // åˆå§‹åŒ–å‡½æ•¸
    bool begin();
    
    // æ•¸æ“šè¼¸å…¥
    void addDataPoint(float* sensor_data);  // æ·»åŠ ä¸€å€‹æ•¸æ“šé» (9ç¶­)
    bool isBufferReady();  // æª¢æŸ¥ç·©è¡å€æ˜¯å¦æº–å‚™å¥½æ¨ç†
    
    // æ¨ç†
    bool runInference();
    
    // çµæœç²å–
    int getPredictedClass();
    float getConfidence();
    float* getAllPredictions();
    String getParkinsonLevelDescription();
    
    // å¯¦ç”¨å‡½æ•¸
    void clearBuffer();
    void printModelInfo();
    void printBufferStatus();
    String getRecommendation();
    
    // æ–°å¢ï¼šç²å–ç·©è¡å€ç‹€æ…‹
    int getBufferFillLevel();
    int getSequenceLength();
};

// æ§‹é€ å‡½æ•¸
TensorFlowLiteInference::TensorFlowLiteInference() {
    model = nullptr;
    interpreter = nullptr;
    resolver = nullptr;
    input = nullptr;
    output = nullptr;
    buffer_index = 0;
    buffer_full = false;
    predicted_class = -1;
    confidence = 0.0;
}

// ææ§‹å‡½æ•¸
TensorFlowLiteInference::~TensorFlowLiteInference() {
    // æ³¨æ„: AllOpsResolverå’ŒMicroInterpreteråœ¨TensorFlow Lite Microä¸­
    // ä½¿ç”¨éœæ…‹åˆ†é…ï¼Œä¸éœ€è¦æ‰‹å‹•delete
    // è®“ç³»çµ±è‡ªå‹•æ¸…ç†é€™äº›å°è±¡
    resolver = nullptr;
    interpreter = nullptr;
}

// åˆå§‹åŒ–
bool TensorFlowLiteInference::begin() {
    // æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
    if (model_data_len < 1000) {
        Serial.println("âš ï¸  ä½¿ç”¨æ¼”ç¤ºæ¨¡å‹é€²è¡Œæ¸¬è©¦");
        Serial.println("AIåŠŸèƒ½å°‡è¿”å›æ¨¡æ“¬çµæœ");
        Serial.println("è¦ç²å¾—çœŸå¯¦AIåŠŸèƒ½ï¼Œè«‹è¨“ç·´å®Œæ•´æ¨¡å‹");
        
        // ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼ - è·³éçœŸå¯¦AIåˆå§‹åŒ–
        Serial.println("âœ… æ¼”ç¤ºæ¨¡å¼åˆå§‹åŒ–æˆåŠŸ");
        return true;  // å…è¨±æ¼”ç¤ºæ¨¡å¼ç¹¼çºŒé‹è¡Œ
    } else {
        Serial.println("âœ… ä½¿ç”¨å®Œæ•´AIæ¨¡å‹");
    }
    
    // åŠ è¼‰æ¨¡å‹
    model = tflite::GetModel(model_data);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        Serial.print("Model schema version ");
        Serial.print(model->version());
        Serial.print(" != supported version ");
        Serial.println(TFLITE_SCHEMA_VERSION);
        return false;
    }
    
    // å‰µå»ºæ“ä½œè§£æå™¨ï¼ˆä½¿ç”¨éœæ…‹åˆ†é…ï¼‰
    static tflite::AllOpsResolver static_resolver;
    resolver = &static_resolver;
    
    // å‰µå»ºè§£é‡‹å™¨ï¼ˆä½¿ç”¨éœæ…‹åˆ†é…ï¼‰
    static tflite::MicroInterpreter static_interpreter(
        model, *resolver, tensor_arena, kTensorArenaSize);
    interpreter = &static_interpreter;
    
    // åˆ†é…å¼µé‡
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    if (allocate_status != kTfLiteOk) {
        Serial.println("AllocateTensors() failed");
        return false;
    }
    
    // ç²å–è¼¸å…¥è¼¸å‡ºå¼µé‡
    input = interpreter->input(0);
    output = interpreter->output(0);
    
    // é©—è­‰å¼µé‡å°ºå¯¸
    if ((input->dims->size != 3) ||
        (input->dims->data[1] != kSequenceLength) ||
        (input->dims->data[2] != kFeatureDim)) {
        Serial.println("Bad input tensor parameters in model");
        return false;
    }
    
    if ((output->dims->size != 2) ||
        (output->dims->data[1] != kNumClasses)) {
        Serial.println("Bad output tensor parameters in model");
        return false;
    }
    
    // æ¸…ç©ºç·©è¡å€
    clearBuffer();
    
    Serial.println("TensorFlow Liteæ¨ç†å¼•æ“åˆå§‹åŒ–æˆåŠŸ");
    return true;
}

// æ·»åŠ æ•¸æ“šé»
void TensorFlowLiteInference::addDataPoint(float* sensor_data) {
    // å°‡9ç¶­æ•¸æ“šæ·»åŠ åˆ°ç·©è¡å€
    for (int i = 0; i < kFeatureDim; i++) {
        input_buffer[buffer_index * kFeatureDim + i] = sensor_data[i];
    }
    
    buffer_index++;
    
    // å¦‚æœç·©è¡å€æ»¿äº†ï¼Œé–‹å§‹æ»‘å‹•çª—å£
    if (buffer_index >= kSequenceLength) {
        buffer_full = true;
        
        // æ»‘å‹•çª—å£ï¼šç§»é™¤æœ€èˆŠçš„æ•¸æ“šé»
        for (int i = 0; i < (kSequenceLength - 1) * kFeatureDim; i++) {
            input_buffer[i] = input_buffer[i + kFeatureDim];
        }
        
        buffer_index = kSequenceLength - 1;
    }
}

// æª¢æŸ¥ç·©è¡å€æ˜¯å¦æº–å‚™å¥½
bool TensorFlowLiteInference::isBufferReady() {
    return buffer_full;
}

// åŸ·è¡Œæ¨ç†
bool TensorFlowLiteInference::runInference() {
    if (!buffer_full) {
        return false;
    }
    
    // æª¢æŸ¥æ˜¯å¦ç‚ºæ¼”ç¤ºæ¨¡å¼
    if (model_data_len < 1000) {
        // æ¼”ç¤ºæ¨¡å¼ - ç”Ÿæˆæ¨¡æ“¬çµæœ
        Serial.println("ğŸ”„ æ¼”ç¤ºæ¨¡å¼æ¨ç†ä¸­...");
        
        // åŸºæ–¼è¼¸å…¥æ•¸æ“šç”Ÿæˆåˆç†çš„æ¨¡æ“¬çµæœ
        float average_activity = 0.0;
        for (int i = 0; i < kSequenceLength * kFeatureDim; i++) {
            average_activity += input_buffer[i];
        }
        average_activity /= (kSequenceLength * kFeatureDim);
        
        // æ¨¡æ“¬å¸•é‡‘æ£®ç­‰ç´šåˆ¤æ–·
        if (average_activity < 0.2) {
            predicted_class = 0;  // è¼•åº¦
            confidence = 0.75;
        } else if (average_activity < 0.4) {
            predicted_class = 1;  // è¼•ä¸­åº¦
            confidence = 0.80;
        } else if (average_activity < 0.6) {
            predicted_class = 2;  // ä¸­åº¦
            confidence = 0.85;
        } else if (average_activity < 0.8) {
            predicted_class = 3;  // ä¸­é‡åº¦
            confidence = 0.82;
        } else {
            predicted_class = 4;  // é‡åº¦
            confidence = 0.78;
        }
        
        // ç”Ÿæˆæ¨¡æ“¬æ¦‚ç‡åˆ†ä½ˆ
        for (int i = 0; i < kNumClasses; i++) {
            predictions[i] = (i == predicted_class) ? confidence : ((1.0 - confidence) / 4.0);
        }
        
        Serial.println("âœ… æ¼”ç¤ºæ¨ç†å®Œæˆ");
        return true;
    }
    
    // çœŸå¯¦AIæ¨¡å‹æ¨ç†ï¼ˆç•¶æœ‰å®Œæ•´æ¨¡å‹æ™‚ï¼‰
    // å°‡æ•¸æ“šè¤‡è£½åˆ°è¼¸å…¥å¼µé‡
    for (int i = 0; i < kSequenceLength * kFeatureDim; i++) {
        if (input->type == kTfLiteFloat32) {
            input->data.f[i] = input_buffer[i];
        } else if (input->type == kTfLiteInt8) {
            // é‡åŒ–è¼¸å…¥ï¼ˆå‡è¨­è¼¸å…¥å·²ç¶“æ¨™æº–åŒ–ï¼‰
            input->data.int8[i] = (int8_t)(input_buffer[i] * 127.0f);
        }
    }
    
    // åŸ·è¡Œæ¨ç†
    TfLiteStatus invoke_status = interpreter->Invoke();
    if (invoke_status != kTfLiteOk) {
        Serial.println("Invoke failed");
        return false;
    }
    
    // æå–çµæœ
    confidence = 0.0;
    predicted_class = 0;
    
    for (int i = 0; i < kNumClasses; i++) {
        if (output->type == kTfLiteFloat32) {
            predictions[i] = output->data.f[i];
        } else if (output->type == kTfLiteInt8) {
            predictions[i] = output->data.int8[i] / 127.0f;
        }
        
        if (predictions[i] > confidence) {
            confidence = predictions[i];
            predicted_class = i;
        }
    }
    
    return true;
}

// ç²å–é æ¸¬é¡åˆ¥
int TensorFlowLiteInference::getPredictedClass() {
    return predicted_class + 1;  // è½‰æ›ç‚º1-5ç­‰ç´š
}

// ç²å–ç½®ä¿¡åº¦
float TensorFlowLiteInference::getConfidence() {
    return confidence;
}

// ç²å–æ‰€æœ‰é æ¸¬æ¦‚ç‡
float* TensorFlowLiteInference::getAllPredictions() {
    return predictions;
}

// ç²å–å¸•é‡‘æ£®ç­‰ç´šæè¿°
String TensorFlowLiteInference::getParkinsonLevelDescription() {
    int level = getPredictedClass();
    
    switch(level) {
        case 1: return "è¼•åº¦ç—‡ç‹€";
        case 2: return "è¼•ä¸­åº¦ç—‡ç‹€";
        case 3: return "ä¸­åº¦ç—‡ç‹€";
        case 4: return "ä¸­é‡åº¦ç—‡ç‹€";
        case 5: return "é‡åº¦ç—‡ç‹€";
        default: return "æœªçŸ¥";
    }
}

// ç²å–è¨“ç·´å»ºè­°
String TensorFlowLiteInference::getRecommendation() {
    int level = getPredictedClass();
    
    switch(level) {
        case 1: 
            return "å»ºè­°é€²è¡Œæº«å’Œçš„éˆæ´»æ€§è¨“ç·´ï¼Œèˆµæ©Ÿé˜»åŠ›è¨­å®š30åº¦";
        case 2: 
            return "å¢åŠ å”èª¿æ€§ç·´ç¿’ï¼Œèˆµæ©Ÿé˜»åŠ›è¨­å®š60åº¦";
        case 3: 
            return "é‡é»æ”¹å–„ç²¾ç´°å‹•ä½œæ§åˆ¶ï¼Œèˆµæ©Ÿé˜»åŠ›è¨­å®š90åº¦";
        case 4: 
            return "åŠ å¼·è‚Œè‚‰åŠ›é‡å’Œå¹³è¡¡è¨“ç·´ï¼Œèˆµæ©Ÿé˜»åŠ›è¨­å®š120åº¦";
        case 5: 
            return "é€²è¡Œè¼”åŠ©æ€§åº·å¾©è¨“ç·´ï¼Œèˆµæ©Ÿé˜»åŠ›è¨­å®š150åº¦";
        default: 
            return "è«‹é‡æ–°é€²è¡Œè©•ä¼°";
    }
}

// æ¸…ç©ºç·©è¡å€
void TensorFlowLiteInference::clearBuffer() {
    buffer_index = 0;
    buffer_full = false;
    predicted_class = -1;
    confidence = 0.0;
    
    for (int i = 0; i < kSequenceLength * kFeatureDim; i++) {
        input_buffer[i] = 0.0;
    }
}

// æ‰“å°æ¨¡å‹ä¿¡æ¯
void TensorFlowLiteInference::printModelInfo() {
    Serial.println("=== TensorFlow Liteæ¨¡å‹ä¿¡æ¯ ===");
    Serial.print("æ¨¡å‹å¤§å°: ");
    Serial.print(model_data_len);
    Serial.println(" bytes");
    Serial.print("è¼¸å…¥å½¢ç‹€: [");
    Serial.print(kSequenceLength);
    Serial.print(", ");
    Serial.print(kFeatureDim);
    Serial.println("]");
    Serial.print("è¼¸å‡ºå½¢ç‹€: [");
    Serial.print(kNumClasses);
    Serial.println("]");
    Serial.print("å¼µé‡Arenaå¤§å°: ");
    Serial.print(kTensorArenaSize);
    Serial.println(" bytes");
}

// æ‰“å°ç·©è¡å€ç‹€æ…‹
void TensorFlowLiteInference::printBufferStatus() {
    Serial.print("ç·©è¡å€ç‹€æ…‹: ");
    Serial.print(buffer_index);
    Serial.print("/");
    Serial.print(kSequenceLength);
    Serial.print(", æº–å‚™æ¨ç†: ");
    Serial.println(buffer_full ? "æ˜¯" : "å¦");
}

// ç²å–ç•¶å‰ç·©è¡å€å¡«å……æ•¸é‡
int TensorFlowLiteInference::getBufferFillLevel() {
    return buffer_index;
}

// ç²å–åºåˆ—é•·åº¦
int TensorFlowLiteInference::getSequenceLength() {
    return kSequenceLength;
}

#endif // TENSORFLOW_LITE_INFERENCE_H