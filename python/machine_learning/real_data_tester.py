"""
çœŸå®è¯­éŸ³æ•°æ®æµ‹è¯•å™¨
ä¸‹è½½GitHubé¡¹ç›®çš„çœŸå®è¯­éŸ³æ•°æ®å¹¶æµ‹è¯•æˆ‘ä»¬çš„ç‰¹å¾æå–å™¨å’Œåˆ†ç±»å™¨
"""

import os
import requests
import numpy as np
from speech_feature_extractor import LightweightSpeechFeatureExtractor
from speech_parkinson_classifier import SpeechParkinsonClassifier
import json

class RealDataTester:
    """çœŸå®æ•°æ®æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.base_url = "https://raw.githubusercontent.com/vitomarcorubino/Parkinsons-detection/master/dataset/train"
        self.data_dir = "data/real_speech_samples"
        self.extractor = LightweightSpeechFeatureExtractor()
        self.classifier = SpeechParkinsonClassifier()
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(f"{self.data_dir}/parkinson", exist_ok=True)
        os.makedirs(f"{self.data_dir}/healthy", exist_ok=True)
    
    def download_sample_files(self, num_samples_per_class=5):
        """ä¸‹è½½æ ·æœ¬éŸ³é¢‘æ–‡ä»¶"""
        print(f"[INFO] ä¸‹è½½çœŸå®è¯­éŸ³æ ·æœ¬...")
        
        # å¸•é‡‘æ£®æ‚£è€…æ ·æœ¬æ–‡ä»¶å
        parkinson_files = [
            "B1ABNINSAC46F240120171753.wav",
            "B1AGNUTGOL52F100220171041.wav", 
            "B1DLAARCII37F100220171111.wav",
            "B1GLIAUDLO50F100220171257.wav",
            "B1GMIAOSVI44M100220170942.wav"
        ]
        
        # å¥åº·äººæ ·æœ¬æ–‡ä»¶å (ä»elderlyHealthyControlè·å–)
        healthy_files = [
            # è¿™äº›éœ€è¦ä»APIè·å–å®é™…æ–‡ä»¶å
        ]
        
        # ä¸‹è½½å¸•é‡‘æ£®æ‚£è€…æ ·æœ¬
        downloaded_parkinson = 0
        for filename in parkinson_files[:num_samples_per_class]:
            url = f"{self.base_url}/peopleWithParkinson/{filename}"
            local_path = f"{self.data_dir}/parkinson/{filename}"
            
            if self.download_file(url, local_path):
                downloaded_parkinson += 1
                print(f"  âœ“ ä¸‹è½½å¸•é‡‘æ£®æ ·æœ¬: {filename}")
            else:
                print(f"  âœ— ä¸‹è½½å¤±è´¥: {filename}")
        
        print(f"[SUCCESS] ä¸‹è½½äº† {downloaded_parkinson} ä¸ªå¸•é‡‘æ£®æ ·æœ¬")
        return downloaded_parkinson > 0
    
    def download_file(self, url, local_path):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        try:
            if os.path.exists(local_path):
                print(f"  æ–‡ä»¶å·²å­˜åœ¨: {os.path.basename(local_path)}")
                return True
                
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            with open(local_path, 'wb') as f:
                f.write(response.content)
            
            return True
            
        except Exception as e:
            print(f"  ä¸‹è½½é”™è¯¯: {e}")
            return False
    
    def test_feature_extraction(self):
        """æµ‹è¯•ç‰¹å¾æå–"""
        print(f"\n[INFO] æµ‹è¯•çœŸå®æ•°æ®ç‰¹å¾æå–...")
        
        parkinson_dir = f"{self.data_dir}/parkinson"
        audio_files = [f for f in os.listdir(parkinson_dir) if f.endswith('.wav')]
        
        if not audio_files:
            print("[WARNING] æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
            return None
        
        features_list = []
        labels_list = []
        
        for audio_file in audio_files:
            file_path = os.path.join(parkinson_dir, audio_file)
            print(f"  å¤„ç†æ–‡ä»¶: {audio_file}")
            
            try:
                # æå–ç‰¹å¾
                features = self.extractor.extract_features_from_file(file_path)
                
                if features is not None and not np.all(features == 0):
                    features_list.append(features)
                    labels_list.append(1)  # å¸•é‡‘æ£®æ‚£è€…
                    
                    print(f"    ç‰¹å¾å‘é‡: {features}")
                    print(f"    ç‰¹å¾åç§°: {self.extractor.get_feature_names()}")
                else:
                    print(f"    ç‰¹å¾æå–å¤±è´¥æˆ–å…¨é›¶")
                    
            except Exception as e:
                print(f"    å¤„ç†é”™è¯¯: {e}")
        
        if features_list:
            features_array = np.array(features_list)
            print(f"\n[SUCCESS] æˆåŠŸæå– {len(features_list)} ä¸ªæ ·æœ¬çš„ç‰¹å¾")
            print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {features_array.shape}")
            
            # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡
            print(f"\nç‰¹å¾ç»Ÿè®¡:")
            for i, name in enumerate(self.extractor.get_feature_names()):
                mean_val = np.mean(features_array[:, i])
                std_val = np.std(features_array[:, i])
                print(f"  {name:15s}: å‡å€¼={mean_val:8.3f}, æ ‡å‡†å·®={std_val:8.3f}")
            
            return features_array, np.array(labels_list)
        else:
            print("[ERROR] æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾")
            return None
    
    def compare_with_synthetic_data(self, real_features):
        """æ¯”è¾ƒçœŸå®æ•°æ®å’Œåˆæˆæ•°æ®çš„ç‰¹å¾åˆ†å¸ƒ"""
        print(f"\n[INFO] æ¯”è¾ƒçœŸå®æ•°æ®ä¸åˆæˆæ•°æ®...")
        
        # ç”Ÿæˆåˆæˆæ•°æ®
        from speech_feature_extractor import create_synthetic_speech_data
        synthetic_X, synthetic_y = create_synthetic_speech_data(100)
        
        # åˆ†ç¦»å¸•é‡‘æ£®å’Œå¥åº·æ ·æœ¬
        synthetic_parkinson = synthetic_X[synthetic_y == 1]
        
        print(f"çœŸå®å¸•é‡‘æ£®æ ·æœ¬æ•°: {len(real_features)}")
        print(f"åˆæˆå¸•é‡‘æ£®æ ·æœ¬æ•°: {len(synthetic_parkinson)}")
        
        print(f"\nç‰¹å¾å¯¹æ¯” (çœŸå® vs åˆæˆ):")
        for i, name in enumerate(self.extractor.get_feature_names()):
            real_mean = np.mean(real_features[:, i])
            synthetic_mean = np.mean(synthetic_parkinson[:, i])
            
            print(f"  {name:15s}: çœŸå®={real_mean:8.3f}, åˆæˆ={synthetic_mean:8.3f}, å·®å¼‚={abs(real_mean-synthetic_mean):8.3f}")
    
    def test_classification(self, real_features, real_labels):
        """æµ‹è¯•åˆ†ç±»æ€§èƒ½"""
        print(f"\n[INFO] æµ‹è¯•åˆ†ç±»å™¨æ€§èƒ½...")
        
        # åŠ è½½æˆ–è®­ç»ƒåˆ†ç±»å™¨
        model_path = "models/speech_parkinson_classifier.json"
        if os.path.exists(model_path):
            self.classifier.load_model(model_path)
            print("  ä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹")
        else:
            print("  æ¨¡å‹ä¸å­˜åœ¨ï¼Œä½¿ç”¨åˆæˆæ•°æ®è®­ç»ƒ...")
            from speech_feature_extractor import create_synthetic_speech_data
            X_train, y_train = create_synthetic_speech_data(1000)
            self.classifier.train(X_train, y_train)
            self.classifier.save_model(model_path)
        
        # æµ‹è¯•çœŸå®æ•°æ®
        print(f"\nçœŸå®æ•°æ®åˆ†ç±»ç»“æœ:")
        correct_predictions = 0
        
        for i, features in enumerate(real_features):
            result = self.classifier.predict(features)
            predicted_class = result['predicted_class']
            confidence = result['confidence']
            actual_class = real_labels[i]
            
            is_correct = predicted_class == actual_class
            if is_correct:
                correct_predictions += 1
            
            print(f"  æ ·æœ¬ {i+1}: é¢„æµ‹={predicted_class} ({'å¸•é‡‘æ£®' if predicted_class==1 else 'å¥åº·'}), "
                  f"å®é™…={actual_class}, ç½®ä¿¡åº¦={confidence:.3f}, "
                  f"{'âœ“' if is_correct else 'âœ—'}")
        
        accuracy = correct_predictions / len(real_features)
        print(f"\nçœŸå®æ•°æ®å‡†ç¡®ç‡: {accuracy:.3f} ({correct_predictions}/{len(real_features)})")
        
        return accuracy
    
    def save_real_data_analysis(self, features, labels):
        """ä¿å­˜çœŸå®æ•°æ®åˆ†æç»“æœ"""
        analysis_data = {
            'num_samples': len(features),
            'feature_names': self.extractor.get_feature_names(),
            'feature_statistics': {},
            'sample_features': features.tolist(),
            'labels': labels.tolist()
        }
        
        # è®¡ç®—ç‰¹å¾ç»Ÿè®¡
        for i, name in enumerate(self.extractor.get_feature_names()):
            analysis_data['feature_statistics'][name] = {
                'mean': float(np.mean(features[:, i])),
                'std': float(np.std(features[:, i])),
                'min': float(np.min(features[:, i])),
                'max': float(np.max(features[:, i]))
            }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = "data/real_data_analysis.json"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        with open(output_path, 'w') as f:
            json.dump(analysis_data, f, indent=2)
        
        print(f"[SUCCESS] çœŸå®æ•°æ®åˆ†æç»“æœå·²ä¿å­˜: {output_path}")

def main():
    """ä¸»ç¨‹åº"""
    print("=== çœŸå®è¯­éŸ³æ•°æ®æµ‹è¯•å™¨ ===")
    
    tester = RealDataTester()
    
    # 1. ä¸‹è½½æ ·æœ¬æ•°æ®
    print("\næ­¥éª¤1: ä¸‹è½½çœŸå®è¯­éŸ³æ ·æœ¬")
    if not tester.download_sample_files(num_samples_per_class=3):
        print("[ERROR] ä¸‹è½½å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # 2. æµ‹è¯•ç‰¹å¾æå–
    print("\næ­¥éª¤2: æµ‹è¯•ç‰¹å¾æå–")
    result = tester.test_feature_extraction()
    if result is None:
        print("[ERROR] ç‰¹å¾æå–å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    real_features, real_labels = result
    
    # 3. æ¯”è¾ƒåˆæˆæ•°æ®
    print("\næ­¥éª¤3: æ¯”è¾ƒåˆæˆæ•°æ®")
    tester.compare_with_synthetic_data(real_features)
    
    # 4. æµ‹è¯•åˆ†ç±»
    print("\næ­¥éª¤4: æµ‹è¯•åˆ†ç±»æ€§èƒ½")
    accuracy = tester.test_classification(real_features, real_labels)
    
    # 5. ä¿å­˜åˆ†æç»“æœ
    print("\næ­¥éª¤5: ä¿å­˜åˆ†æç»“æœ")
    tester.save_real_data_analysis(real_features, real_labels)
    
    print(f"\nâœ… çœŸå®æ•°æ®æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š å¤„ç†æ ·æœ¬æ•°: {len(real_features)}")
    print(f"ğŸ¯ åˆ†ç±»å‡†ç¡®ç‡: {accuracy:.1%}")
    print(f"ğŸ’¡ ä¸‹ä¸€æ­¥: æ ¹æ®çœŸå®æ•°æ®ä¼˜åŒ–ç‰¹å¾æå–å’Œæ¨¡å‹")

if __name__ == "__main__":
    main()
