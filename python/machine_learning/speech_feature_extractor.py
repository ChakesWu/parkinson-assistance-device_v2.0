"""
è½»é‡çº§è¯­éŸ³ç‰¹å¾æå–å™¨
åŸºäºvitomarcorubino/Parkinsons-detectioné¡¹ç›®ï¼Œä¼˜åŒ–ç”¨äºArduino Nano 33 BLE Sense Rev2

ä¸»è¦ç‰¹å¾ï¼š
1. åŸºé¢‘ç»Ÿè®¡ (F0 mean, std)
2. æŠ–åŠ¨ç‰¹å¾ (Jitter)
3. å¾®é¢¤ç‰¹å¾ (Shimmer) 
4. è°å™ªæ¯” (HNR)
5. ç®€åŒ–MFCC (å‰4ç»´)
æ€»è®¡ï¼š8ç»´è½»é‡çº§ç‰¹å¾å‘é‡
"""

import numpy as np
import librosa
import scipy.signal
from scipy.stats import skew, kurtosis
import warnings
warnings.filterwarnings('ignore')

class LightweightSpeechFeatureExtractor:
    """
    è½»é‡çº§è¯­éŸ³ç‰¹å¾æå–å™¨
    ä¸“ä¸ºArduinoéƒ¨ç½²ä¼˜åŒ–ï¼Œæå–æ ¸å¿ƒå¸•é‡‘æ£®è¯­éŸ³ç‰¹å¾
    """
    
    def __init__(self, sample_rate=16000, frame_length=1024, hop_length=512):
        self.sample_rate = sample_rate
        self.frame_length = frame_length
        self.hop_length = hop_length
        self.feature_names = [
            'f0_mean', 'f0_std', 'jitter_local', 'shimmer_local',
            'hnr', 'mfcc_1', 'mfcc_2', 'mfcc_3'
        ]
        
    def extract_f0_features(self, audio):
        """æå–åŸºé¢‘ç›¸å…³ç‰¹å¾"""
        try:
            # ä½¿ç”¨librosaæå–åŸºé¢‘
            f0 = librosa.yin(audio, 
                           fmin=75,    # æœ€å°åŸºé¢‘ (Hz)
                           fmax=500,   # æœ€å¤§åŸºé¢‘ (Hz)
                           sr=self.sample_rate,
                           frame_length=self.frame_length,
                           hop_length=self.hop_length)
            
            # ç§»é™¤æ— æ•ˆå€¼
            f0_valid = f0[f0 > 0]
            
            if len(f0_valid) == 0:
                return 0.0, 0.0
                
            f0_mean = np.mean(f0_valid)
            f0_std = np.std(f0_valid)
            
            return f0_mean, f0_std
            
        except Exception as e:
            print(f"F0æå–é”™è¯¯: {e}")
            return 0.0, 0.0
    
    def extract_jitter(self, audio):
        """æå–æŠ–åŠ¨ç‰¹å¾ (ç®€åŒ–ç‰ˆæœ¬)"""
        try:
            # æå–åŸºé¢‘åºåˆ—
            f0 = librosa.yin(audio, 
                           fmin=75, fmax=500, 
                           sr=self.sample_rate,
                           frame_length=self.frame_length,
                           hop_length=self.hop_length)
            
            # ç§»é™¤æ— æ•ˆå€¼
            f0_valid = f0[f0 > 0]
            
            if len(f0_valid) < 3:
                return 0.0
                
            # è®¡ç®—å‘¨æœŸé—´å˜åŒ–ç‡ (ç®€åŒ–çš„æŠ–åŠ¨)
            periods = 1.0 / f0_valid
            period_diffs = np.abs(np.diff(periods))
            jitter_local = np.mean(period_diffs) / np.mean(periods)
            
            return jitter_local
            
        except Exception as e:
            print(f"Jitteræå–é”™è¯¯: {e}")
            return 0.0
    
    def extract_shimmer(self, audio):
        """æå–å¾®é¢¤ç‰¹å¾ (ç®€åŒ–ç‰ˆæœ¬)"""
        try:
            # è®¡ç®—çŸ­æ—¶èƒ½é‡
            frame_length = int(0.025 * self.sample_rate)  # 25msçª—å£
            hop_length = int(0.010 * self.sample_rate)    # 10msè·³è·ƒ
            
            # åˆ†å¸§
            frames = librosa.util.frame(audio, 
                                      frame_length=frame_length,
                                      hop_length=hop_length,
                                      axis=0)
            
            # è®¡ç®—æ¯å¸§èƒ½é‡
            energy = np.sum(frames**2, axis=1)
            energy = energy[energy > 0]  # ç§»é™¤é™éŸ³å¸§
            
            if len(energy) < 3:
                return 0.0
                
            # è®¡ç®—èƒ½é‡å˜åŒ–ç‡ (ç®€åŒ–çš„å¾®é¢¤)
            energy_diffs = np.abs(np.diff(energy))
            shimmer_local = np.mean(energy_diffs) / np.mean(energy)
            
            return shimmer_local
            
        except Exception as e:
            print(f"Shimmeræå–é”™è¯¯: {e}")
            return 0.0
    
    def extract_hnr(self, audio):
        """æå–è°å™ªæ¯”"""
        try:
            # è®¡ç®—è‡ªç›¸å…³
            autocorr = np.correlate(audio, audio, mode='full')
            autocorr = autocorr[len(autocorr)//2:]
            
            # æ‰¾åˆ°åŸºé¢‘å¯¹åº”çš„å»¶è¿Ÿ
            min_period = int(self.sample_rate / 500)  # 500Hzå¯¹åº”çš„æœ€å°å‘¨æœŸ
            max_period = int(self.sample_rate / 75)   # 75Hzå¯¹åº”çš„æœ€å¤§å‘¨æœŸ
            
            if max_period >= len(autocorr):
                return 0.0
                
            # åœ¨æœ‰æ•ˆèŒƒå›´å†…æ‰¾å³°å€¼
            peak_idx = np.argmax(autocorr[min_period:max_period]) + min_period
            
            # è®¡ç®—è°å™ªæ¯” (ç®€åŒ–ç‰ˆæœ¬)
            signal_power = autocorr[peak_idx]
            noise_power = np.mean(autocorr) - signal_power
            
            if noise_power <= 0:
                return 20.0  # æœ€å¤§HNRå€¼
                
            hnr = 10 * np.log10(signal_power / noise_power)
            return max(0.0, min(20.0, hnr))  # é™åˆ¶åœ¨åˆç†èŒƒå›´
            
        except Exception as e:
            print(f"HNRæå–é”™è¯¯: {e}")
            return 0.0
    
    def extract_mfcc_lite(self, audio):
        """æå–ç®€åŒ–MFCCç‰¹å¾ (å‰3ç»´)"""
        try:
            # è®¡ç®—MFCC
            mfcc = librosa.feature.mfcc(y=audio, 
                                      sr=self.sample_rate,
                                      n_mfcc=4,  # åªå–å‰4ç»´
                                      n_fft=self.frame_length,
                                      hop_length=self.hop_length)
            
            # å–å‡å€¼ (è·³è¿‡ç¬¬0ç»´ï¼Œé€šå¸¸æ˜¯èƒ½é‡)
            mfcc_mean = np.mean(mfcc[1:4], axis=1)  # å–ç¬¬1-3ç»´
            
            return mfcc_mean
            
        except Exception as e:
            print(f"MFCCæå–é”™è¯¯: {e}")
            return np.zeros(3)
    
    def extract_features(self, audio_data):
        """
        æå–å®Œæ•´çš„8ç»´ç‰¹å¾å‘é‡
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ® (numpy array)
            
        Returns:
            features: 8ç»´ç‰¹å¾å‘é‡ [f0_mean, f0_std, jitter, shimmer, hnr, mfcc1, mfcc2, mfcc3]
        """
        try:
            # é¢„å¤„ç†ï¼šå½’ä¸€åŒ–
            if len(audio_data) == 0:
                return np.zeros(8)
                
            audio_data = audio_data.astype(np.float32)
            if np.max(np.abs(audio_data)) > 0:
                audio_data = audio_data / np.max(np.abs(audio_data))
            
            # æå–å„ç±»ç‰¹å¾
            f0_mean, f0_std = self.extract_f0_features(audio_data)
            jitter = self.extract_jitter(audio_data)
            shimmer = self.extract_shimmer(audio_data)
            hnr = self.extract_hnr(audio_data)
            mfcc_features = self.extract_mfcc_lite(audio_data)
            
            # ç»„åˆç‰¹å¾å‘é‡
            features = np.array([
                f0_mean, f0_std, jitter, shimmer, hnr,
                mfcc_features[0], mfcc_features[1], mfcc_features[2]
            ], dtype=np.float32)
            
            # å¤„ç†NaNå’Œæ— ç©·å€¼
            features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)
            
            return features
            
        except Exception as e:
            print(f"ç‰¹å¾æå–å¤±è´¥: {e}")
            return np.zeros(8)
    
    def extract_features_from_file(self, audio_file_path):
        """ä»éŸ³é¢‘æ–‡ä»¶æå–ç‰¹å¾"""
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            audio_data, sr = librosa.load(audio_file_path, sr=self.sample_rate)
            
            # æå–ç‰¹å¾
            features = self.extract_features(audio_data)
            
            return features
            
        except Exception as e:
            print(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            return np.zeros(8)
    
    def get_feature_names(self):
        """è·å–ç‰¹å¾åç§°"""
        return self.feature_names.copy()
    
    def normalize_features(self, features, feature_stats=None):
        """
        ç‰¹å¾æ ‡å‡†åŒ–
        
        Args:
            features: ç‰¹å¾å‘é‡æˆ–ç‰¹å¾çŸ©é˜µ
            feature_stats: é¢„è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯ {'mean': [...], 'std': [...]}
        """
        if feature_stats is None:
            # ä½¿ç”¨é»˜è®¤ç»Ÿè®¡ä¿¡æ¯ (åŸºäºè®­ç»ƒæ•°æ®ä¼°ç®—)
            feature_stats = {
                'mean': np.array([150.0, 30.0, 0.01, 0.05, 10.0, 0.0, 0.0, 0.0]),
                'std': np.array([50.0, 15.0, 0.005, 0.02, 5.0, 1.0, 1.0, 1.0])
            }
        
        features = np.array(features)
        mean = np.array(feature_stats['mean'])
        std = np.array(feature_stats['std'])
        
        # é¿å…é™¤é›¶
        std = np.where(std == 0, 1.0, std)
        
        normalized = (features - mean) / std
        return normalized

def create_synthetic_speech_data(num_samples=1000, feature_extractor=None):
    """
    åˆ›å»ºåˆæˆè¯­éŸ³ç‰¹å¾æ•°æ®ç”¨äºæµ‹è¯•
    æ¨¡æ‹Ÿå¸•é‡‘æ£®æ‚£è€…å’Œå¥åº·äººçš„è¯­éŸ³ç‰¹å¾å·®å¼‚
    """
    if feature_extractor is None:
        feature_extractor = LightweightSpeechFeatureExtractor()

    X = []
    y = []

    print(f"ç”Ÿæˆ {num_samples} ä¸ªåˆæˆè¯­éŸ³ç‰¹å¾æ ·æœ¬...")

    for i in range(num_samples):
        # éšæœºé€‰æ‹©ç±»åˆ« (0: å¥åº·, 1: å¸•é‡‘æ£®)
        label = np.random.randint(0, 2)

        if label == 0:  # å¥åº·äººç‰¹å¾
            f0_mean = np.random.normal(180, 25)      # åŸºé¢‘å‡å€¼
            f0_std = np.random.normal(20, 5)         # åŸºé¢‘æ ‡å‡†å·®
            jitter = np.random.normal(0.005, 0.002)  # æŠ–åŠ¨
            shimmer = np.random.normal(0.03, 0.01)   # å¾®é¢¤
            hnr = np.random.normal(15, 3)            # è°å™ªæ¯”
            mfcc1 = np.random.normal(0, 0.8)         # MFCCç‰¹å¾
            mfcc2 = np.random.normal(0, 0.6)
            mfcc3 = np.random.normal(0, 0.4)
        else:  # å¸•é‡‘æ£®æ‚£è€…ç‰¹å¾
            f0_mean = np.random.normal(160, 35)      # åŸºé¢‘é™ä½ï¼Œå˜å¼‚å¢å¤§
            f0_std = np.random.normal(35, 10)        # åŸºé¢‘ä¸ç¨³å®š
            jitter = np.random.normal(0.015, 0.008)  # æŠ–åŠ¨å¢åŠ 
            shimmer = np.random.normal(0.08, 0.03)   # å¾®é¢¤å¢åŠ 
            hnr = np.random.normal(8, 4)             # è°å™ªæ¯”é™ä½
            mfcc1 = np.random.normal(0.2, 1.0)       # MFCCç‰¹å¾å˜åŒ–
            mfcc2 = np.random.normal(-0.1, 0.8)
            mfcc3 = np.random.normal(0.1, 0.6)

        # ç¡®ä¿ç‰¹å¾åœ¨åˆç†èŒƒå›´å†…
        features = np.array([
            max(50, min(400, f0_mean)),
            max(5, min(100, f0_std)),
            max(0, min(0.1, jitter)),
            max(0, min(0.3, shimmer)),
            max(0, min(25, hnr)),
            max(-3, min(3, mfcc1)),
            max(-3, min(3, mfcc2)),
            max(-3, min(3, mfcc3))
        ])

        X.append(features)
        y.append(label)

    return np.array(X), np.array(y)

def main():
    """æµ‹è¯•è¯­éŸ³ç‰¹å¾æå–å™¨"""
    print("=== è½»é‡çº§è¯­éŸ³ç‰¹å¾æå–å™¨æµ‹è¯• ===")

    # åˆ›å»ºæå–å™¨
    extractor = LightweightSpeechFeatureExtractor()

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("\n1. ç”Ÿæˆåˆæˆæµ‹è¯•æ•°æ®...")
    X, y = create_synthetic_speech_data(100, extractor)

    print(f"ç”Ÿæˆæ•°æ®å½¢çŠ¶: {X.shape}")
    print(f"ç‰¹å¾åç§°: {extractor.get_feature_names()}")

    # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡
    print(f"\n2. ç‰¹å¾ç»Ÿè®¡:")
    for i, name in enumerate(extractor.get_feature_names()):
        healthy_mean = np.mean(X[y==0, i])
        parkinson_mean = np.mean(X[y==1, i])
        print(f"{name:15s}: å¥åº·={healthy_mean:6.3f}, å¸•é‡‘æ£®={parkinson_mean:6.3f}")

    # æµ‹è¯•ç‰¹å¾æ ‡å‡†åŒ–
    print(f"\n3. æµ‹è¯•ç‰¹å¾æ ‡å‡†åŒ–...")
    X_normalized = extractor.normalize_features(X)
    print(f"æ ‡å‡†åŒ–åå‡å€¼: {np.mean(X_normalized, axis=0)}")
    print(f"æ ‡å‡†åŒ–åæ ‡å‡†å·®: {np.std(X_normalized, axis=0)}")

    print(f"\nâœ… è½»é‡çº§è¯­éŸ³ç‰¹å¾æå–å™¨æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š ç‰¹å¾ç»´åº¦: {len(extractor.get_feature_names())}ç»´")
    print(f"ğŸ¯ é€‚åˆArduinoéƒ¨ç½²çš„è½»é‡çº§å®ç°")

if __name__ == "__main__":
    main()
